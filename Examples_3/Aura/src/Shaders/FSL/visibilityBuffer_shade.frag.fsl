/*
 * Copyright (c) 2017-2022 The Forge Interactive Inc.
 *
 * This is a part of Aura.
 * 
 * This file(code) is licensed under a 
 * Creative Commons Attribution-NonCommercial 4.0 International License 
 *
 *   (https://creativecommons.org/licenses/by-nc/4.0/legalcode) 
 *
 * Based on a work at https://github.com/ConfettiFX/The-Forge.
 * You may not use the material for commercial purposes.
*/

#include "packing.h.fsl"
#include "shading.h.fsl"
#include "lpvCommon_example.h.fsl"
#include "wind.h.fsl"

// USERMACRO: USE_LPV [0,1]
// USERMACRO: ENABLE_SUN [0,1]
// Uncomment this definition to use ray differentials method for calculating
// gradients instead of screen-space projected triangles method.
// #define USE_RAY_DIFFERENTIALS
// This shader loads draw / triangle Id per pixel and reconstruct interpolated vertex data.

STRUCT(PsIn)
{
	DATA(float4, position,  SV_Position);
	DATA(float2, screenPos, TEXCOORD0);
};

struct DerivativesOutput
{
	float3 db_dx;
	float3 db_dy;
};

// 2D interpolation results for texture gradient values
struct GradientInterpolationResults
{
	float2 interp;
	float2 dx;
	float2 dy;
};

// Barycentric coordinates and gradients, struct needed to interpolate values.
struct BarycentricDeriv
{
	float3 m_lambda;
	float3 m_ddx;
	float3 m_ddy;
};

// Calculates the local (barycentric coordinates) position of a ray hitting a triangle (Muller-Trumbore algorithm)
// Parameters: p0,p1,p2 -> World space coordinates of triangle
// o -> Origin of ray in world space (Mainly view camera here)
// d-> Unit vector direction of ray from origin
float3 rayTriangleIntersection(float3 p0, float3 p1, float3 p2, float3 o, float3 d)
{
	float3 v0v1 = p1-p0;
	float3 v0v2 = p2-p0;
	float3 pvec = cross(d,v0v2);
	float det = dot(v0v1,pvec);
	float invDet = 1/det;
	float3 tvec = o - p0;
	float u = dot(tvec,pvec) * invDet;
	float3 qvec = cross(tvec,v0v1);
	float v = dot(d,qvec) *invDet;
	float w = 1.0f - v - u;
	return float3(w,u,v);
}

// Computes the partial derivatives of a triangle from the projected screen space vertices
BarycentricDeriv CalcFullBary(float4 pt0, float4 pt1, float4 pt2, float2 pixelNdc, float2 winSize)
{
	BarycentricDeriv ret ;
	float3 invW =  1.0f / float3(pt0.w, pt1.w, pt2.w);
	//Project points on screen to calculate post projection positions in 2D
	float2 ndc0 = pt0.xy * invW.x;
	float2 ndc1 = pt1.xy * invW.y;
	float2 ndc2 = pt2.xy * invW.z;

	// Computing partial derivatives and prospective correct attribute interpolation with barycentric coordinates
	// Equation for calculation taken from Appendix A of DAIS paper:
	// https://cg.ivd.kit.edu/publications/2015/dais/DAIS.pdf

	// Calculating inverse of determinant(rcp of area of triangle).
	float invDet = rcp(determinant(float2x2(ndc2 - ndc1, ndc0 - ndc1)));

	//determining the partial derivatives
	// ddx[i] = (y[i+1] - y[i-1])/Determinant
	ret.m_ddx = float3(ndc1.y - ndc2.y, ndc2.y - ndc0.y, ndc0.y - ndc1.y) * invDet * invW;
	ret.m_ddy = float3(ndc2.x - ndc1.x, ndc0.x - ndc2.x, ndc1.x - ndc0.x) * invDet * invW;
	// sum of partial derivatives.
	float ddxSum = dot(ret.m_ddx, float3(1,1,1));
	float ddySum = dot(ret.m_ddy, float3(1,1,1));
	
	// Delta vector from pixel's screen position to vertex 0 of the triangle.
	float2 deltaVec = pixelNdc - ndc0;

	// Calculating interpolated W at point.
	float interpInvW = invW.x + deltaVec.x*ddxSum + deltaVec.y*ddySum;
	float interpW = rcp(interpInvW);
	// The barycentric co-ordinate (m_lambda) is determined by perspective-correct interpolation. 
	// Equation taken from DAIS paper.
	ret.m_lambda.x = interpW * (invW[0] + deltaVec.x*ret.m_ddx.x + deltaVec.y*ret.m_ddy.x);
	ret.m_lambda.y = interpW * (0.0f    + deltaVec.x*ret.m_ddx.y + deltaVec.y*ret.m_ddy.y);
	ret.m_lambda.z = interpW * (0.0f    + deltaVec.x*ret.m_ddx.z + deltaVec.y*ret.m_ddy.z);

	//Scaling from NDC to pixel units
	ret.m_ddx *= (2.0f/winSize.x);
	ret.m_ddy *= (2.0f/winSize.y);
	ddxSum    *= (2.0f/winSize.x);
	ddySum    *= (2.0f/winSize.y);

	// This part fixes the derivatives error happening for the projected triangles.
	// Instead of calculating the derivatives constantly across the 2D triangle we use a projected version
	// of the gradients, this is more accurate and closely matches GPU raster behavior.
	// Final gradient equation: ddx = (((lambda/w) + ddx) / (w+|ddx|)) - lambda

	// Calculating interpW at partial derivatives position sum.
	float interpW_ddx = 1.0f / (interpInvW + ddxSum);
	float interpW_ddy = 1.0f / (interpInvW + ddySum);

	// Calculating perspective projected derivatives.
	ret.m_ddx = interpW_ddx*(ret.m_lambda*interpInvW + ret.m_ddx) - ret.m_lambda;
	ret.m_ddy = interpW_ddy*(ret.m_lambda*interpInvW + ret.m_ddy) - ret.m_lambda;  

	return ret;
}

// Helper functions to interpolate vertex attributes using derivatives.

// Interpolate a float3 vector.
float InterpolateWithDeriv(BarycentricDeriv deriv, float3 v)
{
	return dot(v,deriv.m_lambda);
}
// Interpolate single values over triangle vertices.
float InterpolateWithDeriv(BarycentricDeriv deriv, float v0, float v1, float v2)
{
	float3 mergedV = float3(v0, v1, v2);
	return InterpolateWithDeriv(deriv,mergedV);
}

// Interpolate a float3 attribute for each vertex of the triangle.
// Attribute parameters: a 3x3 matrix (Row denotes attributes per vertex).
float3 InterpolateWithDeriv(BarycentricDeriv deriv,f3x3 attributes)
{
	float3 attr0 = getCol0(attributes);
	float3 attr1 = getCol1(attributes);
	float3 attr2 = getCol2(attributes);
	return float3(dot(attr0,deriv.m_lambda),dot(attr1,deriv.m_lambda),dot(attr2,deriv.m_lambda));
}

// Interpolate 2D attributes using the partial derivatives and generates dx and dy for texture sampling.
// Attribute paramters: a 3x2 matrix of float2 attributes (Column denotes attribuets per vertex).
GradientInterpolationResults Interpolate2DWithDeriv(BarycentricDeriv deriv,f3x2 attributes)
{
	float3 attr0 = getRow0(attributes);
	float3 attr1 = getRow1(attributes);
	
	GradientInterpolationResults result;
	// independently interpolate x and y attributes.
	result.interp.x = InterpolateWithDeriv(deriv,attr0);
	result.interp.y = InterpolateWithDeriv(deriv,attr1);

	// Calculate attributes' dx and dy (for texture sampling).
	result.dx.x = dot(attr0,deriv.m_ddx);
	result.dx.y = dot(attr1,deriv.m_ddx);
	result.dy.x = dot(attr0,deriv.m_ddy);
	result.dy.y = dot(attr1,deriv.m_ddy);
	return result;
}

// Calculate ray differentials for a point in world-space
// Parameters: pt0,pt1,pt2 -> world space coordinates of the triangle currently visible on the pixel
// position -> world-space calculated position of the current pixel by reconstructing Z value
// positionDX,positionDY -> world-space positions a pixel footprint right and down of the calculated position w.r.t traingle
BarycentricDeriv CalcRayBary(float3 pt0, float3 pt1, float3 pt2,float3 position,float3 positionDX,float3 positionDY,
								float3 camPos)
{
	BarycentricDeriv ret ;

	// Calculating unit vector directions of all 3 rays
	float3 curRay = position - camPos;
	float3 rayDX = positionDX - camPos;
	float3 rayDY = positionDY - camPos;
	// Calculating barycentric coordinates of each rays hitting the triangle
	float3 H = rayTriangleIntersection(pt0,pt1,pt2,camPos,normalize(curRay));
	float3 Hx = rayTriangleIntersection(pt0,pt1,pt2,camPos,normalize(rayDX));
	float3 Hy = rayTriangleIntersection(pt0,pt1,pt2,camPos,normalize(rayDY));
	ret.m_lambda = H;
	// Ray coordinates differential
	ret.m_ddx = Hx-H;
	ret.m_ddy = Hy-H;
	return ret;
}

float depthLinearization(float depth, float near, float far)
{
	return (2.0 * near) / (far + near - depth * (far - near));
}


RES(Tex2D(float4), vbTex,     UPDATE_FREQ_NONE, t0, binding = 0);
RES(Tex2D(float),  shadowMap, UPDATE_FREQ_NONE, t1, binding = 1);

RES(ByteBuffer,            vertexPos,           UPDATE_FREQ_NONE, t2, binding = 2);
RES(ByteBuffer,            vertexTexCoord,      UPDATE_FREQ_NONE, t3, binding = 3);
RES(ByteBuffer,            vertexNormal,        UPDATE_FREQ_NONE, t4, binding = 4);
RES(ByteBuffer,            vertexTangent,       UPDATE_FREQ_NONE, t5, binding = 5);
RES(Buffer(MeshConstants), meshConstantsBuffer, UPDATE_FREQ_NONE, t6, binding = 6);
RES(Buffer(LightData),     lights,              UPDATE_FREQ_NONE, t7, binding = 7);
RES(SamplerState,          textureSampler,      UPDATE_FREQ_NONE, s0, binding = 8);
RES(SamplerState,          depthSampler,        UPDATE_FREQ_NONE, s1, binding = 9);
RES(SamplerState,          linearBorderSampler, UPDATE_FREQ_NONE, s2, binding = 10);

#if defined(METAL) || defined(ORBIS) || defined(PROSPERO)
	RES(Tex2D(float4), diffuseMaps[MATERIAL_BUFFER_SIZE],  UPDATE_FREQ_NONE, t0, binding = 10);
	RES(Tex2D(float4), normalMaps[MATERIAL_BUFFER_SIZE],   UPDATE_FREQ_NONE, t1, binding = 10);
	RES(Tex2D(float4), specularMaps[MATERIAL_BUFFER_SIZE], UPDATE_FREQ_NONE, t2, binding = 10);
#else
	RES(Tex2D(float4), diffuseMaps[MATERIAL_BUFFER_SIZE],  space4, t0, binding = 11);
	RES(Tex2D(float4), normalMaps[MATERIAL_BUFFER_SIZE],   space5, t0, binding = 11 + MAX_TEXTURE_UNITS);
	RES(Tex2D(float4), specularMaps[MATERIAL_BUFFER_SIZE], space6, t0, binding = 11 + MAX_TEXTURE_UNITS * 2);
#endif

RES(ByteBuffer,   filteredIndexBuffer,    UPDATE_FREQ_PER_FRAME, t0, binding = 1);
RES(Buffer(uint), indirectMaterialBuffer, UPDATE_FREQ_PER_FRAME, t1, binding = 2);
RES(Buffer(uint), indirectDrawArgs[2],    UPDATE_FREQ_PER_FRAME, t2, binding = 3);
RES(ByteBuffer,   lightClustersCount,     UPDATE_FREQ_PER_FRAME, t4, binding = 5);
RES(ByteBuffer,   lightClusters,          UPDATE_FREQ_PER_FRAME, t5, binding = 6);

CBUFFER(auraApplyLightData, UPDATE_FREQ_PER_FRAME, b1, binding = 7)
{
	DATA(LightApplyData, lightApplyData, None);
};

#include "lpvLightApply.h.fsl"

float4 PS_MAIN(PsIn In)
{
	INIT_MAIN;
	// Load Visibility Buffer raw packed float4 data from render target
	float4 visRaw = LoadTex2D(Get(vbTex), Get(depthSampler), uint2(In.position.xy), 0);
	// Unpack float4 render target data into uint to extract data
	uint alphaBit_drawID_triID = packUnorm4x8(visRaw);

	// Early exit if this pixel doesn't contain triangle data
	if (alphaBit_drawID_triID == ~0u)
	{
		discard;
	}

	// Extract packed data
	uint drawID = (alphaBit_drawID_triID >> 23) & 0x000000FF;
	uint triangleID = (alphaBit_drawID_triID & 0x007FFFFF);
	uint alpha1_opaque0 = (alphaBit_drawID_triID >> 31);

	// This is the start vertex of the current draw batch
	uint startIndexOffset = INDIRECT_DRAW_ARGUMENTS_STRUCT_OFFSET + 2;
	uint startIndex = alpha1_opaque0 == 0 ?
		Get(indirectDrawArgs)[0][drawID * INDIRECT_DRAW_ARGUMENTS_STRUCT_NUM_ELEMENTS + startIndexOffset] :
		Get(indirectDrawArgs)[1][drawID * INDIRECT_DRAW_ARGUMENTS_STRUCT_NUM_ELEMENTS + startIndexOffset];

	// BaseMaterialBuffer returns constant offset values
	// The following value defines the maximum amount of indirect draw calls that will be 
	// drawn at once. This value depends on the number of submeshes or individual objects 
	// in the scene. Changing a scene will require to change this value accordingly.
	// #define MAX_DRAWS_INDIRECT 300 
	//
	// These values are offsets used to point to the material data depending on the 
	// type of geometry and on the culling view
	// #define MATERIAL_BASE_ALPHA0 0
	// #define MATERIAL_BASE_NOALPHA0 MAX_DRAWS_INDIRECT
	// #define MATERIAL_BASE_ALPHA1 (MAX_DRAWS_INDIRECT*2)
	// #define MATERIAL_BASE_NOALPHA1 (MAX_DRAWS_INDIRECT*3)
	uint materialBaseSlot = BaseMaterialBuffer(alpha1_opaque0 == 1, VIEW_CAMERA);

	// potential results for materialBaseSlot + drawID are
	// 0 - 299 - shadow alpha
	// 300 - 599 - shadow no alpha
	// 600 - 899 - camera alpha
	uint materialID = Get(indirectMaterialBuffer)[materialBaseSlot + drawID];

	uint triIdx0 = (triangleID * 3 + 0) + startIndex;
	uint triIdx1 = (triangleID * 3 + 1) + startIndex;
	uint triIdx2 = (triangleID * 3 + 2) + startIndex;

	uint index0 = LoadByte(Get(filteredIndexBuffer), triIdx0 << 2);
	uint index1 = LoadByte(Get(filteredIndexBuffer), triIdx1 << 2);
	uint index2 = LoadByte(Get(filteredIndexBuffer), triIdx2 << 2);

	// Load vertex data of the 3 vertices
	float3 v0pos = LoadVertex(Get(vertexPos), index0).xyz;
	float3 v1pos = LoadVertex(Get(vertexPos), index1).xyz;
	float3 v2pos = LoadVertex(Get(vertexPos), index2).xyz;

	// Apply wind tranform iuf mateiral ID matches cloth
	if (materialID == CLOTH_ID)
	{
		v0pos.xyz = WindTransformWorldPosition(v0pos.xyz, Get(windData));
		v1pos.xyz = WindTransformWorldPosition(v1pos.xyz, Get(windData));
		v2pos.xyz = WindTransformWorldPosition(v2pos.xyz, Get(windData));
	}

	// Transform positions to clip space
	float4 pos0 = mul(Get(transform)[VIEW_CAMERA].mvp, float4(v0pos, 1.0f));
	float4 pos1 = mul(Get(transform)[VIEW_CAMERA].mvp, float4(v1pos, 1.0f));
	float4 pos2 = mul(Get(transform)[VIEW_CAMERA].mvp, float4(v2pos, 1.0f));

	// Calculate vertices' world coordinates
	float4 wPos0 = mul(Get(transform)[VIEW_CAMERA].invVP,pos0);
	float4 wPos1 = mul(Get(transform)[VIEW_CAMERA].invVP,pos1);
	float4 wPos2 = mul(Get(transform)[VIEW_CAMERA].invVP,pos2);

	// Calculate the inverse of w, since it's going to be used several times
	float3 one_over_w = 1.0f / float3(pos0.w, pos1.w, pos2.w);

	// Project vertex positions to calculate 2D post-perspective positions
	pos0 *= one_over_w[0];
	pos1 *= one_over_w[1];
	pos2 *= one_over_w[2];

	float2 pos_scr[3] = { pos0.xy, pos1.xy, pos2.xy };

	// Compute partial derivatives. This is necessary to interpolate triangle attributes per pixel.
	BarycentricDeriv derivativesOut = CalcFullBary(pos0,pos1,pos2,In.screenPos,Get(cullingViewports)[VIEW_CAMERA].windowSize);
	
	// Interpolate the 1/w (one_over_w) for all three vertices of the triangle
	// using the barycentric coordinates and the delta vector
	float w = 1.0f / dot(one_over_w,derivativesOut.m_lambda);

	// Reconstruct the Z value at this screen point performing only the necessary matrix * vector multiplication
	// operations that involve computing Z
	float z = w * getElem(Get(transform)[VIEW_CAMERA].projection, 2, 2) + getElem(Get(transform)[VIEW_CAMERA].projection, 3, 2);

	// Calculate the world position coordinates:
	// First the projected coordinates at this point are calculated using In.screenPos and the computed Z value at this point.
	// Then, multiplying the perspective projected coordinates by the inverse view-projection matrix (invVP) produces world coordinates
	float3 position = mul(Get(transform)[VIEW_CAMERA].invVP, float4(In.screenPos * w, z, w)).xyz;

	// TEXTURE COORD INTERPOLATION
#if defined(USE_RAY_DIFFERENTIALS)
	// We don't apply perspective correction to texture coordinates in case of ray differentials
	f3x2 texCoords = make_f3x2_cols(
			unpack2Floats(LoadByte(Get(vertexTexCoord), index0 << 2)) ,
			unpack2Floats(LoadByte(Get(vertexTexCoord), index1 << 2)) ,
			unpack2Floats(LoadByte(Get(vertexTexCoord), index2 << 2)) 
	);
	float3 positionDX = mul(Get(transform)[VIEW_CAMERA].invVP, float4((In.screenPos+Get(twoOverRes).x/2) * w, z, w)).xyz;
	float3 positionDY = mul(Get(transform)[VIEW_CAMERA].invVP, float4((In.screenPos+Get(twoOverRes).y/2) * w, z, w)).xyz;

	derivativesOut = CalcRayBary(wPos0.xyz,wPos1.xyz,wPos2.xyz,position,positionDX,positionDY,
												Get(camPos).xyz);
#else
	// Apply perspective correction to texture coordinates
	f3x2 texCoords = make_f3x2_cols(
			unpack2Floats(LoadByte(Get(vertexTexCoord), index0 << 2)) * one_over_w[0] ,
			unpack2Floats(LoadByte(Get(vertexTexCoord), index1 << 2)) * one_over_w[1],
			unpack2Floats(LoadByte(Get(vertexTexCoord), index2 << 2)) * one_over_w[2]
	);
#endif

	// Interpolate texture coordinates and calculate the gradients for texture sampling with mipmapping support
	GradientInterpolationResults results = Interpolate2DWithDeriv(derivativesOut,texCoords);

			
	float linearZ = depthLinearization(z/w, Get(CameraPlane).x, Get(CameraPlane).y);
	float mip = pow(pow(linearZ, 0.9f) * 5.0f, 1.5f);
	
	float2 texCoordDX = results.dx * mip;
	float2 texCoordDY = results.dy * mip;
	float2 texCoord = results.interp ;

#if !defined(USE_RAY_DIFFERENTIALS)
	//Perspective correct in case of screen differentials
	texCoord *= w;
	texCoordDX *= w;
	texCoordDY *= w;
#endif
	

	/////////////LOAD///////////////////////////////
	// TANGENT INTERPOLATION
#if defined(USE_RAY_DIFFERENTIALS)
	// We don't apply perspective correction in case of ray differentials
	float3x3 tangents = make_f3x3_rows(
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index0 << 2))) ,
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index1 << 2))),
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index2 << 2))) 
	);
#else
	float3x3 tangents = make_f3x3_rows(
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index0 << 2))) * one_over_w[0],
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index1 << 2))) * one_over_w[1],
			decodeDir(unpackUnorm2x16(LoadByte(Get(vertexTangent), index2 << 2))) * one_over_w[2]
	);

#endif
	float3 tangent = normalize(InterpolateWithDeriv(derivativesOut,tangents));
	
	// CALCULATE PIXEL COLOR USING INTERPOLATED ATTRIBUTES
	// Reconstruct normal map Z from X and Y
	// "NonUniformResourceIndex" is a "pseudo" function see
	// http://asawicki.info/news_1608_direct3d_12_-_watch_out_for_non-uniform_resource_index.html

	// Get textures from arrays.
	float4 normalMapRG;
	float4 diffuseColor;
	float4 specularColor;
	BeginNonUniformResourceIndex(materialID, MAX_TEXTURE_UNITS);
		normalMapRG   = SampleGradTex2D(Get(normalMaps)[materialID],   Get(textureSampler), texCoord, texCoordDX, texCoordDY);
		diffuseColor  = SampleGradTex2D(Get(diffuseMaps)[materialID],  Get(textureSampler), texCoord, texCoordDX, texCoordDY);
		specularColor = SampleGradTex2D(Get(specularMaps)[materialID], Get(textureSampler), texCoord, texCoordDX, texCoordDY);
	EndNonUniformResourceIndex();

	float3 reconstructedNormalMap;
	reconstructedNormalMap.xy = normalMapRG.ga * 2.0f - 1.0f;
	reconstructedNormalMap.z  = sqrt(1 - dot(reconstructedNormalMap.xy, reconstructedNormalMap.xy));

	// NORMAL INTERPOLATION
#if defined(USE_RAY_DIFFERENTIALS)
	// We don't apply perspective correction in case of ray differentials
	float3x3 normals = make_f3x3_rows(
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index0 << 2))) ,
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index1 << 2))) ,
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index2 << 2))) 
	);
#else
	float3x3 normals = make_f3x3_rows(
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index0 << 2))) * one_over_w[0],
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index1 << 2))) * one_over_w[1],
		decodeDir(unpackUnorm2x16(LoadByte(Get(vertexNormal), index2 << 2))) * one_over_w[2]
	);
#endif
	float3 normal = normalize(InterpolateWithDeriv(derivativesOut, normals));

	if (materialID == CLOTH_ID)
	{
		normal  = WindTransformWorldNormal(normal,  position, Get(windData));
		tangent = WindTransformWorldNormal(tangent, position, Get(windData));
	}

	// Calculate vertex binormal from normal and tangent
	float3 binormal = normalize(cross(tangent, normal));

	// Calculate pixel normal using the normal map and the tangent space vectors
	normal = reconstructedNormalMap.x * tangent + reconstructedNormalMap.y * binormal + reconstructedNormalMap.z * normal;

	// Sample Diffuse color
	float4 posLS = mul(Get(transform)[VIEW_SHADOW].vp, float4(position, 1.0f));
	
	float Roughness = clamp(specularColor.a, 0.05f, 0.99f);
	float Metallic = specularColor.b;

	bool isTwoSided = (alpha1_opaque0 == 1) && bool(Get(meshConstantsBuffer)[materialID].twoSided);
	bool isBackFace = false;

	float3 ViewVec = normalize(Get(camPos).xyz - position.xyz);
	
	//if it is backface
	//this should be < 0 but our mesh's edge normals are smoothed, badly
	if (isTwoSided && dot(normal, ViewVec) < 0.0f)
	{
		//flip normal
		normal = -normal;
		isBackFace = true;
	}

	float3 HalfVec = normalize(ViewVec - Get(lightDir).xyz);
	float3 ReflectVec = reflect(-ViewVec, normal);
	float NoV = saturate(dot(normal, ViewVec));

	float NoL = dot(normal, -Get(lightDir).xyz);

	// Deal with two faced materials
	NoL = (isTwoSided ? abs(NoL) : saturate(NoL));

	float3 shadedColor = f3(0.0f);

	float3 F0 = specularColor.xyz;
	float3 DiffuseColor = diffuseColor.xyz;
	float shadowFactor = 1.0f;
	float fLightingMode = saturate(float(Get(lightingMode)));

#if ENABLE_SUN
	shadedColor = calculateIllumination(
                                        normal,
                                        ViewVec,
                                        HalfVec,
                                        ReflectVec,
                                        NoL,
                                        NoV,
                                        Get(camPos).xyz,
                                        Get(esmControl),
                                        Get(lightDir).xyz,
                                        posLS,
                                        position,
                                        Get(shadowMap),
                                        DiffuseColor,
                                        F0,
                                        Roughness,
                                        Metallic,			
                                        Get(depthSampler),
                                        isBackFace,
                                        fLightingMode,
                                        shadowFactor);
		
	shadedColor = shadedColor * Get(lightColor).rgb * Get(lightColor).a * NoL;
#endif
	// point lights
	// Find the light cluster for the current pixel
	uint2 clusterCoords = uint2(floor((In.screenPos * 0.5f + 0.5f) * float2(LIGHT_CLUSTER_WIDTH, LIGHT_CLUSTER_HEIGHT)));

	uint numLightsInCluster = LoadByte(Get(lightClustersCount), LIGHT_CLUSTER_COUNT_POS(clusterCoords.x, clusterCoords.y) << 2);

	// Accumulate light contributions
	for (uint j = 0; j < numLightsInCluster; ++j)
	{
		uint lightId = LoadByte(Get(lightClusters), LIGHT_CLUSTER_DATA_POS(j, clusterCoords.x, clusterCoords.y) << 2);

		shadedColor += pointLightShade(
                                       normal,
                                       ViewVec,
                                       HalfVec,
                                       ReflectVec,
                                       NoL,
                                       NoV,
                                       Get(lights)[lightId].position.xyz,
                                       Get(lights)[lightId].color.xyz,
                                       Get(camPos).xyz,
                                       Get(lightDir).xyz,
                                       posLS,
                                       position,
                                       DiffuseColor,
                                       F0,
                                       Roughness,
                                       Metallic,		
                                       isBackFace,
                                       fLightingMode);
	}

#if USE_LPV
	AuraIndirectLight indirectLight;
	indirectLight.diffuse  = float4(0.0f, 0.0f, 0.0f, 1.0f);
	indirectLight.specular = float4(0.0f, 0.0f, 0.0f, 1.0f);

	for (uint j = 0; j < Get(lightApplyData).cascadeCount; ++j)
	{
		Aura_ApplyLightForCascade(
                                  j,
                                  position,
                                  normal,
                                  Get(lightApplyData).normalScale,
                                  Get(lightApplyData).cascade[j].WorldToGridScale,
                                  Get(lightApplyData).cascade[j].WorldToGridTranslate,
                                  Get(lightApplyData).cascade[j].smoothGridPosOffset,
                                  Get(lightApplyData).camPos,
                                  Get(lightApplyData).cascade[j].lightScale,
                                  Get(lightApplyData).GIStrength,
                                  Get(lightApplyData).lumScale.x,
                                  Get(lightApplyData).lumScale.y,
                                  Get(lightApplyData).lumScale.z,
                                  Get(lightApplyData).cascade[j].cellFalloff,
                                  int(Get(specularQuality)),
                                  Get(linearBorderSampler),
                                  indirectLight);
	}

	shadedColor += diffuseColor.xyz * indirectLight.diffuse.xyz;
	shadedColor += diffuseColor.xyz * indirectLight.specular.xyz;
#endif

	RETURN(float4(shadedColor, 1.0f));
}


